{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytical linear fit:\n",
    "This Python macro illustrates how to perform a linear fit **analytically**, i.e. without any minimisation (e.g. by Minuit), and thus much faster. This can be done, since one can differentiate the Chi2, set this to zero and solve for both intercept and slope.\n",
    "\n",
    "## References:\n",
    "- Note on course webpage\n",
    "- Bevington: Chapter 6\n",
    "\n",
    "## Author(s), contact(s), and dates:\n",
    "- Author: Troels C. Petersen (NBI)\n",
    "- Email:  petersen@nbi.dk\n",
    "- Date:   14th of November 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from iminuit import Minuit\n",
    "from iminuit.cost import LeastSquares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random                         # Random generator\n",
    "r.seed(42)                            # Set a random seed (but a fixed one - more on that later.)\n",
    "save_plots = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nexp = 10       # Number of datasets fitted\n",
    "Npoints = 9\n",
    "alpha0 = 3.6\n",
    "alpha1 = 0.3\n",
    "sigmay = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating and fitting data:\n",
    "In the following, we generate data points following a simple line and fit these both **analytically** and **numerically**. The linear fit (and only this) can be done analytically, as discussed in Barlow chapter 6.2 and outlined here: http://www.nbi.dk/~petersen/Teaching/Stat2024/Notes/StraightLineFit.pdf.\n",
    "The numerical fit of the line (and any other function) is done iteratively by Minuit. The code is slightly shorter, but a lot slower, as the code will typically test many (50+) possible combination of fit parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop, repeating the data generation and fit:\n",
    "for iexp in range(Nexp) : \n",
    "\n",
    "    # Generating data by filling values into (x,y) and associated uncertainty in y:\n",
    "    x = np.arange(Npoints)+1\n",
    "    y = alpha0 + alpha1*x + r.normal(0, sigmay, Npoints) #+ alpha2*x**2\n",
    "    ey = sigmay*np.ones_like(x)\n",
    "\n",
    "    # ------------------------------------------------------------------ #\n",
    "    # Analytical fit:\n",
    "    # ------------------------------------------------------------------ #\n",
    "    # Calculate the relevant sums (see note linked to above):\n",
    "    sum = len(x)\n",
    "    sumx = np.sum(x)\n",
    "    sumxx = np.sum(x**2)\n",
    "    sumy = np.sum(y)\n",
    "    sumxy = np.sum(x*y)\n",
    "    \n",
    "    # Use sums in calculations of the fit parameters:\n",
    "    Delta = sumxx * sum - sumx**2\n",
    "    alpha0_calc = (sumy  * sumxx - sumxy * sumx) / Delta\n",
    "    alpha1_calc = (sumxy * sum   - sumy  * sumx) / Delta\n",
    "    sigma_alpha0_calc = sigmay * np.sqrt(sumxx / Delta)\n",
    "    sigma_alpha1_calc = sigmay * np.sqrt(sumx  / Delta)\n",
    "\n",
    "    # So now you have data points and a fit/theory. How to get the fit quality?\n",
    "    # The answer is to calculate the Chi2 and Ndof, and from these two values get their\n",
    "    # probability using the ChiSquare function (e.g. from scipy):\n",
    "    Chi2_calc = 0.0\n",
    "    for i in range( Npoints ) : \n",
    "        fit_value = alpha0_calc + alpha1_calc * x[i]\n",
    "        Chi2_calc += ((y[i] - fit_value) / ey[i])**2\n",
    "    \n",
    "    Nvar = 2                     # Number of variables (alpha0 and alpha1)\n",
    "    Ndof_calc = Npoints - Nvar   # Number of degrees of freedom = Number of data points - Number of variables\n",
    "    \n",
    "    # From Chi2 and Ndof, one can calculate the probability of obtaining this\n",
    "    # or something worse (i.e. higher Chi2). This is a good function to have!\n",
    "    # We will discuss in class, why/how this function works, and how it plays a central role in statistics.\n",
    "    from scipy import stats\n",
    "    Prob_calc =  stats.chi2.sf(Chi2_calc, Ndof_calc) # The chi2 probability given N degrees of freedom (Ndof)\n",
    "\n",
    "    \n",
    "    # ------------------------------------------------------------------ #\n",
    "    # Numerical fit (i.e. with iMinuit):\n",
    "    # ------------------------------------------------------------------ #\n",
    "    # Define a fit function:\n",
    "    def fit_function(x, alpha0, alpha1):\n",
    "        return alpha0 + alpha1*x\n",
    "\n",
    "    # Now we define a ChiSquare to be minimised, using the iminuit cost function:\n",
    "    chi2_object_function = LeastSquares(x, y, ey, fit_function)\n",
    "    \n",
    "    # Here we let Minuit know, what to minimise, how, and with what starting parameters:   \n",
    "    mfit = Minuit(chi2_object_function, alpha0=3.0, alpha1=0.5)     # iminuits function\n",
    "\n",
    "    # Perform the actual fit (without printing anything):\n",
    "    mfit.print_level = 0\n",
    "    mfit.migrad()\n",
    "\n",
    "    # Record the fit parameters:\n",
    "    alpha0_fit = mfit.values['alpha0']\n",
    "    alpha1_fit = mfit.values['alpha1']\n",
    "    sigma_alpha0_fit = mfit.errors['alpha0']\n",
    "    sigma_alpha1_fit = mfit.errors['alpha1']\n",
    "    \n",
    "    # In Minuit, you can just ask the fit function for the chi2 (or likelihood) value:\n",
    "    Chi2_fit = mfit.fval                          # The chi2 value\n",
    "    Prob_fit = stats.chi2.sf(Chi2_fit, Ndof_calc) # The chi2 probability given N degrees of freedom (Ndof, taken from above!)\n",
    "    \n",
    "    # Let us see what the fit gives for the first couple of datasets:\n",
    "    if (iexp < 10) :\n",
    "        print(f\"  Ana. Fit: a0={alpha0_calc:6.3f}+-{sigma_alpha0_calc:5.3f}  a1={alpha1_calc:5.3f}+-{sigma_alpha1_calc:5.3f}  p={Prob_calc:6.4f}\"+\n",
    "              f\"  Num. Fit: a0={alpha0_fit:6.3f}+-{sigma_alpha0_fit:5.3f}  a1={alpha1_fit:5.3f}+-{sigma_alpha1_fit:5.3f}  p={Prob_fit:6.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.errorbar(x, y, ey, fmt='ro', ecolor='k', elinewidth=1, capsize=2, capthick=1)\n",
    "ax.plot(x, fit_function(x, *mfit.values), '-r')\n",
    "plt.close()\n",
    "\n",
    "fit_info = [f'alpha0 = {alpha0_fit:5.3f}' + r'$\\pm$' +  f\"{sigma_alpha0_fit:5.3f}\",\n",
    "            f'alpha1 = {alpha1_fit:5.3f}' + r'$\\pm$' + f\"{sigma_alpha1_fit:5.3f}\",\n",
    "            f'Chi2 = {Chi2_fit:5.3f}',\n",
    "            f'Ndof = {Ndof_calc:d}',\n",
    "            f'Prob = {Prob_fit:5.3f}',\n",
    "]\n",
    "ax.text(0.05, 0.76, \"\\n\".join(fit_info), fontsize=14, transform = ax.transAxes)\n",
    "fig.tight_layout()\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (save_plots) :\n",
    "    fig.savefig('AnalyticalLinearFit.pdf', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "---------------------------------------------------------------------------------- \n",
    "\n",
    "\n",
    "# Questions:\n",
    "\n",
    "1) Do the analytical result(s) (Calc) agree with the numerical one(s) (Fit)?\n",
    "\n",
    "### Advanced questions:\n",
    "\n",
    "2) Can you measure/determine the difference in speed between the two methods?"
   ]
  }
 ],
 "metadata": {
  "executable": "/usr/bin/env python",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "main_language": "python"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
